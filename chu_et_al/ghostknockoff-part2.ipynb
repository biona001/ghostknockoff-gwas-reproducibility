{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Knockoff sampling + GhostBasil\n",
    "\n",
    "Over 1703 quasi-independent blocks, we have assembled\n",
    "\\begin{align*}\n",
    "    \\Sigma =\n",
    "    \\begin{bmatrix}\n",
    "        \\Sigma_1 & & \\\\\n",
    "        & \\ddots & \\\\\n",
    "        & & \\Sigma_{1703}\n",
    "    \\end{bmatrix}, \\quad\n",
    "    S = \n",
    "    \\begin{bmatrix}\n",
    "        S_1 & & \\\\\n",
    "        & \\ddots & \\\\\n",
    "        & & S_{1703}\n",
    "    \\end{bmatrix}, \\quad\n",
    "    S_i = \n",
    "    \\begin{bmatrix}\n",
    "        S_{i,1} & & \\\\\n",
    "        & \\ddots & \\\\\n",
    "        & & S_{i,G_i}\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "where $\\Sigma_i$ are LD matrices obtained from the Pan-UKBB panel and $S_i$ is the group-block-diagonal matrices obtained by solving the knockoff optimization problem. Given a Z-score vector $z$, we can compute $r = \\frac{1}{\\sqrt{n}} z$, and `ghostbasil` will solve the following problem with $\\lambda \\ge 0, p_i \\ge 0$, and $0 \\le \\alpha \\le 1$.\n",
    "\n",
    "\\begin{align*}\n",
    "\\min \\frac{1}{2}\\beta^t A \\beta - \\beta^tr + \\lambda\\sum_ip_i\\left(\\alpha|\\beta_i| + \\frac{1-\\alpha}{2}\\beta_i^2\\right)\n",
    "\\end{align*}\n",
    "\n",
    "Here $A = \\frac{1}{n}[X,\\tilde{X}]'[X,\\tilde{X}]$ and $\\beta$ contains the effect size for both original variables and their knockoffs. \n",
    "\n",
    "To solve this problem, we will call `ghostbasil(A, r)` where\n",
    "\\begin{align*}\n",
    "    A &= \\text{BlockBlockGroupGhostMatrix}(B_1, ..., B_{1703})\\\\\n",
    "    B_i &= \\text{BlockGroupGhostMatrix}(C_i, S_i, m+1)\\\\\n",
    "    C_i &= \\Sigma_i - S_i\n",
    "\\end{align*}  \n",
    "Note that Jame's function\n",
    "\\begin{align*}\n",
    "    \\text{BlockGroupGhostMatrix}(C, S, n.groups) = \n",
    "    \\begin{bmatrix}\n",
    "        C+S & C & ... & C\\\\\n",
    "        C & C+S & ... & \\\\\n",
    "        \\vdots & & \\ddots & \\vdots\\\\\n",
    "        C & C & & C + S\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "Thus we have\n",
    "\\begin{align*}\n",
    "    A = \n",
    "    \\begin{bmatrix}\n",
    "        B_1 & & \\\\\n",
    "        & \\ddots & \\\\\n",
    "        & & B_{1703}\n",
    "    \\end{bmatrix}, \\quad\n",
    "    B_i = \n",
    "    \\begin{bmatrix}\n",
    "        \\Sigma_i & \\Sigma_i-S_i & ... & \\Sigma_i-S_i\\\\\n",
    "        \\Sigma_i-S_i & \\Sigma_i & ... & \\\\\n",
    "        \\vdots & & \\ddots & \\vdots\\\\\n",
    "        \\Sigma_i-S_i & \\Sigma_i-S_i & & \\Sigma_i\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix}\n",
    "        C_i+S_i & C_i & ... & C_i\\\\\n",
    "        C_i & C_i+S_i & ... & \\\\\n",
    "        \\vdots & & \\ddots & \\vdots\\\\\n",
    "        C_i & C_i & & C_i + S_i\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software versions\n",
    "\n",
    "Code was tested on Sherlock with \n",
    "+ `julia/1.8.4`\n",
    "+ `R/4.0.2`\n",
    "+ `openssl/3.0.7`\n",
    "\n",
    "More Z scores available at:\n",
    "+ https://github.com/mikegloudemans/gwas-download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script\n",
    "\n",
    "+ The script below runs the knockoff sampling + ghostbasil procedure. \n",
    "+ Directories to pre-computed knockoff statistics and Albuminuria Z scores are hard-coded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ml julia/1.8.4 R/4.0.2 openssl/3.0.7\n",
    "\n",
    "using GhostKnockoffGWAS\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Random\n",
    "\n",
    "# helper function to import albuminuria GWAS z-scores\n",
    "function read_phenotype_zscores()\n",
    "    # albuminuria study: https://pubmed.ncbi.nlm.nih.gov/30220432\n",
    "    file = \"/oak/stanford/groups/zihuai/GWAS_Summary_Gloudemans/Albuminuria_Haas_2018/Albuminuria_Haas_2018.txt.gz\"\n",
    "    info = CSV.read(file, DataFrame)\n",
    "    chr = info[!, \"chr\"]\n",
    "    pos = info[!, \"snp_pos\"]\n",
    "    non_effect_allele = info[!, \"non_effect_allele\"] |> Vector{String}\n",
    "    effect_allele = info[!, \"effect_allele\"] |> Vector{String}\n",
    "    pvals = info[!, \"pvalue\"]\n",
    "    betas = info[!, \"beta\"]\n",
    "    z = pval2zscore(pvals, betas)\n",
    "    Neffect = 382500\n",
    "    hg_build = 38\n",
    "\n",
    "    # remove NaN/Inf\n",
    "    idx = findall(x -> !isnan(x) && !isinf(x), z)\n",
    "    return z[idx], chr[idx], pos[idx], effect_allele[idx], non_effect_allele[idx], Neffect, hg_build\n",
    "end\n",
    "\n",
    "# helper function to summarize result\n",
    "function summary_result(outfile::String, target_fdr=0.1)\n",
    "    result = CSV.read(outfile, DataFrame)\n",
    "    pheno_name = basename(outfile)[1:end-4] # no .txt\n",
    "\n",
    "    #\n",
    "    # Manhattan analysis: find most significant SNP within blocks of 1Mb\n",
    "    # \n",
    "    Mb = 1e6\n",
    "    label_idx = Int[]\n",
    "    for chr in 1:22\n",
    "        chr_idx = findall(x -> x == chr, result[!, \"chr\"])\n",
    "        pos = result[chr_idx, :pos_hg19]\n",
    "        blocks = div.(pos, Mb)\n",
    "        for block in unique(blocks)\n",
    "            block_idx = findall(x -> x == block, blocks)\n",
    "            pvals = result[chr_idx[block_idx], :pvals]\n",
    "            pval, pval_idx = findmin(pvals)\n",
    "            if pval < 5e-8\n",
    "                push!(label_idx, chr_idx[block_idx[pval_idx]])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # label significant SNPs\n",
    "    marginal_signif_snps = length(result[label_idx, :rsid])\n",
    "\n",
    "    #\n",
    "    # Knockoff analysis\n",
    "    # \n",
    "    summary = CSV.read(joinpath(dirname(outfile), pheno_name * \"_summary.txt\"), DataFrame, header=false)\n",
    "    if target_fdr == 0.05\n",
    "        q = summary[3, 2] # target FDR 0.05\n",
    "    elseif target_fdr == 0.1\n",
    "        q = summary[5, 2] # target FDR 0.1\n",
    "    elseif target_fdr == 0.2\n",
    "        q = summary[9, 2] # target FDR 0.2\n",
    "    end\n",
    "\n",
    "    # optional: keep only W â‰¥ 0\n",
    "    result = result[findall(x -> x > 0, result[!, :W]), :]\n",
    "\n",
    "    # for each group, only keep SNP with largest Z score\n",
    "    keep_idx = Int[]\n",
    "    for g in unique(result[!, \"group\"])\n",
    "        idx = findall(x -> x == g, result[!, \"group\"])\n",
    "        zscores = result[idx, \"zscores\"]\n",
    "        z, z_idx = findmax(abs.(zscores))\n",
    "        push!(keep_idx, idx[z_idx])\n",
    "    end\n",
    "    result = result[keep_idx, :]\n",
    "\n",
    "    # find most significant SNP within blocks of 1Mb\n",
    "    Mb = 1e6\n",
    "    label_idx = Int[]\n",
    "    result[!, \"gene\"] = [\"\" for i in 1:size(result, 1)]\n",
    "    for chr in 1:22\n",
    "        chr_idx = findall(x -> x == chr, result[!, \"chr\"])\n",
    "        pos = result[chr_idx, :pos_hg19]\n",
    "        blocks = div.(pos, Mb)\n",
    "        for block in unique(blocks)\n",
    "            block_idx = findall(x -> x == block, blocks)\n",
    "            Ws = result[chr_idx[block_idx], :W]\n",
    "            w, w_idx = findmax(Ws)\n",
    "            if w > q\n",
    "                push!(label_idx, chr_idx[block_idx[w_idx]])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # knockoff significant SNPs\n",
    "    ko_signif_snps = length(result[label_idx, :rsid])\n",
    "    nregions = summary[12, 2]\n",
    "    nsnps = summary[13, 2]\n",
    "    return marginal_signif_snps, ko_signif_snps, nregions, nsnps\n",
    "end\n",
    "\n",
    "#\n",
    "# read phenotype z scores\n",
    "#\n",
    "phenotype = \"albuminuria\"\n",
    "LDpopulation = \"EUR\"\n",
    "seed = 1\n",
    "pseudo_validate = true\n",
    "LD_shrinkage = false\n",
    "z, chr, pos, effect_allele, non_effect_allele, Neffect, hg_build = read_phenotype_zscores()\n",
    "knockoff_dir = \"/oak/stanford/groups/zihuai/pan_ukb_group_knockoffs/$LDpopulation\"\n",
    "outdir = joinpath(knockoff_dir, \"results\")\n",
    "\n",
    "#\n",
    "# run analysis\n",
    "#\n",
    "Random.seed!(seed)\n",
    "outfile = \"$(phenotype)_seed$seed\"\n",
    "ghostbasil(knockoff_dir, z, chr, pos, \n",
    "    effect_allele, non_effect_allele, Neffect, hg_build, outdir, \n",
    "    pseudo_validate=pseudo_validate, LD_shrinkage=LD_shrinkage,\n",
    "    outname=outfile, seed=seed)\n",
    "\n",
    "#\n",
    "# summarize result\n",
    "#\n",
    "marginal_signif, ko_signif, nregions, nsnps = \n",
    "    summary_result(joinpath(outdir, outfile * \".txt\"))\n",
    "open(joinpath(outdir, \"$(outfile)_independent_discoveries.txt\"), \"w\") do io\n",
    "    println(io, \"marginal_signif,$(marginal_signif)\")\n",
    "    println(io, \"ko_signif,$(ko_signif)\")\n",
    "    println(io, \"nsnps,$(nsnps)\")\n",
    "    println(io, \"nregions,$(nregions)\")\n",
    "end\n",
    "\n",
    "println(\"finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
